{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01.Transformer_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethan0625/NLP_mini_project/blob/main/01.Transformer_Chatbot/01_Transformer_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGK7q7Wce6iU"
      },
      "source": [
        "# 한국어 데이터로 챗봇 만들기\n",
        "# Trnsformer_Chatbot\n",
        "***\n",
        "## 프로젝트 요약\n",
        "- 해당 프로젝트는 Transformer를 기반으로 한 Single turn 형태의 챗봇을 구현한 프로젝트입니다.    \n",
        "- 영어 데이터셋과 한국어 데이터셋의 차이를 이해하고, 전처리과정에서 한글데이터는 어떤 특징을 갖는지 학습며 챗봇 모델의 기본구조를 이해하는데 목표를 두었습니다.  \n",
        "\n",
        "## Dataset\n",
        "- [송영숙님의 챗봇 데이터](https://github.com/songys/Chatbot_data)를 사용하였습니다.  \n",
        "- 문답 페어 11,823개를 활용하였습니다.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ojf501MUIV-"
      },
      "source": [
        "### [Step 1] 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgWLg-fFI9Yy",
        "outputId": "b4cc83a4-476a-4ba0-8441-1e916f125ffd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlOPWaErUbVW"
      },
      "source": [
        "해당 프로젝트는 구글 코랩에서 작업하여 구글드라이브에서 데이터를 관리하였습니다.  \n",
        "구글드라이브에서 데이터를 불러오는 [Jake님의 블로그](http://growthj.link/python-%EA%B5%AC%EA%B8%80-colab%EC%9C%BC%EB%A1%9C-pd-read-csv-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/)를 참조하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQN6SL4re6iV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dj-CLc9Te6iW",
        "outputId": "065180d4-4fb7-4fe3-ffcf-c44f8f48d0c3"
      },
      "source": [
        "# 데이터 가져오기\n",
        "# chat_filepath =  '/content/drive/MyDrive/aiffel/data/songys_chatbot/Chatbot_data/ChatbotData .csv'\n",
        "chat_filepath = '/aiffel/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
        "chat_data = pd.read_csv(chat_filepath, sep=',')\n",
        "chat_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQoFdY7UVD_L"
      },
      "source": [
        "해당 데이터는 질의, 답변, 감정분류(label)의 칼럼을 가지고 있습니다.  \n",
        "간단한 챗봇모델을 만드는 것이 목표이기때문에 감정분류는 학습데이터에서 제외할 것입니다.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue8WTIghe6iX"
      },
      "source": [
        "### [Step 2] 데이터 전처리하기\n",
        "- 학습에 사용할 데이터는 한국어 데이터입니다.  \n",
        "- 기본적인 전처리(특수문자 제거, 중복 단어 제거, 띄어쓰기 조절 등) 진행 후 문장을 토큰화하고 이를 정수화 하여 학습데이터로 사용할 예정입니다.\n",
        "- 한국어 데이터의 경우 영어 데이터와는 다르게 띄어쓰기로 단어가 분류되지 않습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9bIVOc3kE9R"
      },
      "source": [
        "#### 1) 데이터 전처리\n",
        " 학습에 사용할 데이터는 어느정도 정제된 데이터이므로 간단한 전처리 과정을 거칩니다.  \n",
        " 전처리 과정에서는 아래의 과정을 거치게됩니다.  \n",
        " \n",
        "\n",
        "> (1) 단어와 구두점(punctuation) 사이의 거리를 만듭니다.  \n",
        "> (2) 한글, 영어, 숫자, 문장의 의미를 해치지 않는 특수문자를 제외한 모든 문자를 공백으로 대체합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upecgxjle6iX"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9?.!,]\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpBUD1Fde6iY",
        "outputId": "d98627f4-4c25-4cb5-96db-12ddb7d2cee5"
      },
      "source": [
        "clean_Q=[]\n",
        "for s in chat_data['Q']:\n",
        "    clean_Q.append(preprocess_sentence(s))\n",
        "clean_Q[:5], len(clean_Q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네'],\n",
              " 11823)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-N0DohZe6iZ",
        "outputId": "d067c8ba-eb27-44d9-cf19-e91afa46b6e7"
      },
      "source": [
        "clean_A=[]\n",
        "for s in chat_data['A']:\n",
        "    clean_A.append(preprocess_sentence(s))\n",
        "clean_A[:5], len(clean_A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .'],\n",
              " 11823)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noaTOXzXe6iZ",
        "outputId": "de0f0d7f-ba5e-4710-e4fe-307efb05166e"
      },
      "source": [
        "print('전체 샘플 수(질문) :', len(clean_Q))\n",
        "print('전체 샘플 수(답변) :', len(clean_A))\n",
        "print('전처리 후의 50번째 질문 샘플: {}'.format(clean_Q[49]))\n",
        "print('전처리 후의 50번째 답변 샘플: {}'.format(clean_A[49]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플 수(질문) : 11823\n",
            "전체 샘플 수(답변) : 11823\n",
            "전처리 후의 50번째 질문 샘플: 감 말랭이 먹고 싶다 .\n",
            "전처리 후의 50번째 답변 샘플: 맛있게 드세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHDCGkOuXLV3"
      },
      "source": [
        "#### 2) 한국어 데이터와 영어 데이터의 차이\n",
        "일반적으로 자연어처리는 텍스트를 '토큰 단위'로 나누어서 진행하게 됩니다.  \n",
        "단순하게 '토큰'을 만들어내는 방법은 '띄어쓰기'가 있습니다.  \n",
        "아래와 같이 'I am a student'라는 영어문장과 '나는 학생입니다'라는 한국어 문장이 있습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al8R-ajaYHuR"
      },
      "source": [
        "eng_sen = 'I am a student'\n",
        "kor_sen = '나는 학생입니다'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_AgwfhBYgLX"
      },
      "source": [
        "띄어쓰기로 토큰을 만들어 정리하면 아래와 같습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWxTqPegYykQ",
        "outputId": "62e5b979-5cf9-4691-ba76-b1dcf1b29a6f"
      },
      "source": [
        "eng_token = eng_sen.split()\n",
        "kor_token = kor_sen.split()\n",
        "print('엉어 토큰 :',eng_token)\n",
        "print('한국어 토큰 :',kor_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "엉어 토큰 : ['I', 'am', 'a', 'student']\n",
            "한국어 토큰 : ['나는', '학생입니다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak9ARIrqZM7O"
      },
      "source": [
        "영어의 경우는 단순히 띄어쓰기로도 어느정도 명확하게 분류가 되지만, 한국어의 경우는 그렇지 않습니다.  \n",
        "위에서 확인하였듯이 '나는 학생입니다'라는 문장은 '나', '는', '학생', '입니다'로 나뉘어져야 좀 더 명확하게 분류된다는 것을 알 수 있습니다.    \n",
        "이러한 한국어의 특성때문에 한국어로 자연어처리를 하는 경우에는 보통 형태소 분석을 사용합니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LobLPhpGaPQr"
      },
      "source": [
        "#### 3) 형태소 분석\n",
        "형태소란 언어에 있어서 '최소 의미 단위'를 말합니다.  \n",
        "일반적으로 자연어처리에서 형태소 분석이라함은 형태소를 분석하는 것이 아니라 문장을 형태소로 분석한다는 의미입니다.  \n",
        "형태소 분석은 보통 상용되고있는 형태소 분석기를 활용하여 진행합니다.  \n",
        "형태소 분석기는 'khaiii', 'Hannanum', 'KOMORAN', 'OKT', 'mecab' 등과 같은 여러가지 형태소 분석기가 있습니다.  \n",
        "해당 프로젝트에서는 영어 데이터를 토큰화하는 데 사용하는 'SubwordTextEncoder'와 'mecab'을 사용하여 비교해볼 예정입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NODQbL7aky1r"
      },
      "source": [
        "##### 3-1) SubwordTextEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAkPBAsBe6ib"
      },
      "source": [
        "sub_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(clean_Q + clean_A, target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjI76Y_Imjx2"
      },
      "source": [
        "한국어 데이터셋을 기반으로 단어사전을 만들어 주었기때문에 시작, 종료 토큰이 존재하지 않습니다.  \n",
        "따라서 별개로 정수를 부여해주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbPSSnZje6ib",
        "outputId": "6a3bde2e-cd09-4994-9cc7-a238a125341d"
      },
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "sub_START_TOKEN, sub_END_TOKEN = [sub_tokenizer.vocab_size], [sub_tokenizer.vocab_size + 1]\n",
        "print('sub_START_TOKEN의 번호 :' ,[sub_tokenizer.vocab_size])\n",
        "print('sub_END_TOKEN의 번호 :' ,[sub_tokenizer.vocab_size + 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sub_START_TOKEN의 번호 : [8172]\n",
            "sub_END_TOKEN의 번호 : [8173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx2Q40Zspq-m"
      },
      "source": [
        "총 단어사전의 크기는 시작, 종료 토큰을 추가해서 총 갯수에 +2를 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsf1NLEue6ib"
      },
      "source": [
        "sub_VOCAB_SIZE = sub_tokenizer.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtxHi31Bqoqj"
      },
      "source": [
        "길이가 너무 긴 경우에는 학습이 어려울 수 있으니 최대길이를 정해 학습에 용이하도록 수정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvQGAxJe6ic"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "    cnt = 0\n",
        "    for s in nested_list:\n",
        "        if(len(s.split()) <= max_len):\n",
        "            cnt = cnt + 1\n",
        "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEFz-OXXe6ic"
      },
      "source": [
        "MAX_LENGTH = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VhdvB5Fe6ic"
      },
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def sub_tokenize_and_filter(inputs, outputs):\n",
        "    tokenized_inputs, tokenized_outputs = [], []\n",
        "    \n",
        "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "        sentence1 = sub_START_TOKEN + sub_tokenizer.encode(sentence1) + sub_END_TOKEN\n",
        "        sentence2 = sub_START_TOKEN + sub_tokenizer.encode(sentence2) + sub_END_TOKEN\n",
        "\n",
        "        # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
        "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "            tokenized_inputs.append(sentence1)\n",
        "            tokenized_outputs.append(sentence2)\n",
        "\n",
        "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
        "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "    return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjGsrl1Ce6id",
        "outputId": "4769e1e5-f442-462c-bc49-8f70a4e267fd"
      },
      "source": [
        "sub_clean_Q, sub_clean_A = sub_tokenize_and_filter(clean_Q, clean_A)\n",
        "print('단어장의 크기 :',(sub_VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(sub_clean_Q)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(sub_clean_A)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어장의 크기 : 8174\n",
            "필터링 후의 질문 샘플 개수: 11823\n",
            "필터링 후의 답변 샘플 개수: 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET9zRe0Wrz8W",
        "outputId": "164720b8-b151-4865-a675-ccf5fc860940"
      },
      "source": [
        "sub_clean_Q[49]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([8172, 3172,  307, 8151, 8074, 8089,   11,  129,   67,    1, 8173,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9MsHJr-WxsH9",
        "outputId": "28c03f60-33ca-4e14-dc2a-269540ad1382"
      },
      "source": [
        "sub_tokenizer.decode([i for i in sub_clean_Q[49]if i < sub_tokenizer.vocab_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'감 말랭이 먹고 싶다 .'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWJabiv0e6id"
      },
      "source": [
        "# 교사강요 사용\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "sub_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': sub_clean_Q,\n",
        "        'dec_inputs': sub_clean_A[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': sub_clean_A[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "sub_dataset = sub_dataset.cache()\n",
        "sub_dataset = sub_dataset.shuffle(BUFFER_SIZE)\n",
        "sub_dataset = sub_dataset.batch(BATCH_SIZE)\n",
        "sub_dataset = sub_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fomSsu_3p32E"
      },
      "source": [
        "여기까지 SubwordTextEncoder를 활용하여 학습 데이터셋을 구성하였습니다.  \n",
        "이제 mecab을 활용하여 구성해 보겠습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w68sdvoIyL5Z"
      },
      "source": [
        "##### 3-2) mecab\n",
        "mecab의 경우 따로 설치를 진행해주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7NNef4fynje",
        "outputId": "ff8e5ee2-02ca-4669-9703-84157d31d43d"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n",
            "/aiffel/aiffel/transformer_chatbot/Mecab-ko-for-Google-Colab\n",
            "install_mecab-ko_on_colab190912.sh: line 4: cd: /content: No such file or directory\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /opt/conda/lib/python3.7/site-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (2.25.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
            "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-08-18 23:53:55--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::34cc:ea4a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=fyT2GpnaQTNU%2FWhehovnaGPs2Lk%3D&Expires=1629332635&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-08-18 23:53:55--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=fyT2GpnaQTNU%2FWhehovnaGPs2Lk%3D&Expires=1629332635&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.104.212\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.104.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  6.38MB/s    in 0.2s    \n",
            "\n",
            "2021-08-18 23:53:55 (6.38 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-08-18 23:55:10--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::34cc:ea4a, 2406:da00:ff00::22c2:513, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=pSYF0MhiKoRyBY9BunzZ63Y37%2F4%3D&Expires=1629332542&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-08-18 23:55:11--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=pSYF0MhiKoRyBY9BunzZ63Y37%2F4%3D&Expires=1629332542&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.174.57\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.174.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  46.8MB/s    in 1.0s    \n",
            "\n",
            "2021-08-18 23:55:12 (46.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxhFIi6EzPFs"
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab=Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SusFiS52vcv"
      },
      "source": [
        "# 정수 인코딩을 실제로 진행하기 위한 함수\n",
        "def get_encoded_sentence(sentence, word_to_index):\n",
        "    return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence]\n",
        "    \n",
        "# Q,A 칼럼에서 한문장씩 가져와 정수 인코딩 함수를 적용하여 return하는 함수\n",
        "def vectorize(corpus, word_to_index):\n",
        "    data = []\n",
        "    for sen in corpus:\n",
        "        sen = get_encoded_sentence(sen, word_to_index)\n",
        "        data.append(sen)\n",
        "    return data\n",
        "\n",
        "\n",
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def mec_tokenize_and_filter(inputs, outputs):\n",
        "    tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "        # 정수 인코딩 과정 전 시작 토큰과 종료 토큰을 추가\n",
        "        sentence1 = ['<BOS>'] + mecab.morphs(sentence1) + ['<EOS>']\n",
        "        sentence2 = ['<BOS>'] + mecab.morphs(sentence2) + ['<EOS>']\n",
        "\n",
        "        # 최대 길이 40이하인 경우에만 데이터셋으로 허용       \n",
        "        if len(sentence1) <= 42 and len(sentence2) <= 42:\n",
        "            tokenized_inputs.append(sentence1)\n",
        "            tokenized_outputs.append(sentence2)\n",
        "\n",
        "    print('최대길이 조절 후 input > ',len(tokenized_inputs))\n",
        "    print('최대길이 조절 후 output > ', len(tokenized_outputs))\n",
        "\n",
        "    total = tokenized_inputs + tokenized_outputs\n",
        "    words = np.concatenate(total).tolist()\n",
        "    counter = Counter(words)\n",
        "    counter = counter.most_common(30000-2)\n",
        "    vocab = ['<PAD>','<UNK>']+[key for key,_ in counter]\n",
        "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
        "    index_to_word = {index:word for word, index in word_to_index.items()}\n",
        "\n",
        "    tokenized_inputs = vectorize(tokenized_inputs,word_to_index)\n",
        "    tokenized_outputs = vectorize(tokenized_outputs,word_to_index)\n",
        "\n",
        "\n",
        "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
        "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "    \n",
        "    return tokenized_inputs, tokenized_outputs, word_to_index, index_to_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LKxZFaky4Wm",
        "outputId": "671400f2-ce8c-4360-a0fe-35c35d644361"
      },
      "source": [
        "mec_Q, mec_A, word_to_index, index_to_word = mec_tokenize_and_filter(clean_Q,clean_A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최대길이 조절 후 input >  11823\n",
            "최대길이 조절 후 output >  11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vd0K5LkzyOL",
        "outputId": "958c0bea-deb8-4457-82de-9280026d8f35"
      },
      "source": [
        "mec_Q[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   2, 2339,  174, 3338,   85,    3,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2,  282, 3339,  532,  996,   11,    3,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2,  299, 2077,  533,   60,  209,  234,   10,   12,   38,   30,\n",
              "           3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2,  299, 2077,  533,   60,  444,  209,  234,   10,   12,   38,\n",
              "          30,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2, 4687,  900,   41,    3,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1dHA7GKz4Yj",
        "outputId": "0adc057e-5079-4e6e-b363-17a6a97870fe"
      },
      "source": [
        "mec_A[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   2,  247,   10,  146,   10,   36,    4,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2,  521,   15, 1497,    4,    3,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2,  236,   18,  701,   13,   34,    4,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2,  236,   18,  701,   13,   34,    4,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   2, 4194,    5, 4195,   19,   34,    4,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mipc0Giz0Cdg",
        "outputId": "4b1e1b77-f753-478f-ff44-512d2d96f4e9"
      },
      "source": [
        "mec_VOCAB_SIZE = len(word_to_index)\n",
        "print('mecab활용 Vocab_size :',len(word_to_index))\n",
        "print('mecab활용 Q_corpus :',len(mec_Q))\n",
        "print('mecab활용 A_corpus :',len(mec_A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mecab활용 Vocab_size : 6840\n",
            "mecab활용 Q_corpus : 11823\n",
            "mecab활용 A_corpus : 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CP_VRkzJ_qo"
      },
      "source": [
        "# 교사강요 사용\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "mec_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': mec_Q,\n",
        "        'dec_inputs': mec_A[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': mec_A[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "mec_dataset = mec_dataset.cache()\n",
        "mec_dataset = mec_dataset.shuffle(BUFFER_SIZE)\n",
        "mec_dataset = mec_dataset.batch(BATCH_SIZE)\n",
        "mec_dataset = mec_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-3YS70ve6ie"
      },
      "source": [
        "***\n",
        "### [Step 3] 모델 구성하기\n",
        "- 학습에 활용되는 모델은 트랜스포머로 아래의 함수들은 프랜스포머를 구현하기 위한 함수들입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bY6hc-ze6ie"
      },
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model)\n",
        "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J1uaidTe6ie"
      },
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    \"\"\"어텐션 가중치를 계산. \"\"\"\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # add the mask to zero out padding tokens\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmtaAo7pe6ie"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # linear layers\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # 스케일드 닷 프로덕트 어텐션 함수\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # final linear layer\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4S3sgkSe6if"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf7qEOQCe6if"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQIZ3IMAe6if"
      },
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "    # 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "    attention = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "        })\n",
        "\n",
        "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTNdG4vAe6if"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 임베딩 레이어\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "    # 포지셔널 인코딩\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # num_layers만큼 쌓아올린 인코더의 층.\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnYry6xie6ig"
      },
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "    attention1 = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "            'query': inputs,\n",
        "            'key': inputs,\n",
        "            'value': inputs,\n",
        "            'mask': look_ahead_mask\n",
        "        })\n",
        "\n",
        "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "    attention2 = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "            'query': attention1,\n",
        "            'key': enc_outputs,\n",
        "            'value': enc_outputs,\n",
        "            'mask': padding_mask\n",
        "        })\n",
        "\n",
        "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs,name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyeZBcLe6ig"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "    # 패딩 마스크\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 임베딩 레이어\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "    # 포지셔널 인코딩\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs,name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVsSnrWe6ig"
      },
      "source": [
        "모델 구성에 필요한 함수들을 다 만들었으니 이제 모델을 구성하여 학습시켜보겠습니다.  \n",
        "학습데이터를 토큰화하는데 2가지의 토크나이저를 사용하였으니 이에따라 모델을 나누어 학습을 진행하겠습니다.  \n",
        "#### 1) SubwordTextEncoder 모델구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYNBnvI3e6ig"
      },
      "source": [
        "#모델 정의 및 학습하기\n",
        "def sub_transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"sub_transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    # 인코더에서 패딩을 위한 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='enc_padding_mask')(inputs)\n",
        "\n",
        "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "        create_look_ahead_mask,\n",
        "        output_shape=(1, None, None),\n",
        "        name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "    # 디코더에서 패딩을 위한 마스크\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='dec_padding_mask')(inputs)\n",
        "\n",
        "    # 인코더\n",
        "    enc_outputs = encoder(\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=num_layers,\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    # 디코더\n",
        "    dec_outputs = decoder(\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=num_layers,\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    # 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71kKxy68e6ig",
        "outputId": "fa1e583d-b898-4905-c1a4-f09b09367283"
      },
      "source": [
        "#모델 생성\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "sub_model = sub_transformer(\n",
        "    vocab_size=sub_VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "sub_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sub_transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 512)    13652992    inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, None, 512)    19962880    dec_inputs[0][0]                 \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 8174)   4193262     decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 37,809,134\n",
            "Trainable params: 37,809,134\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLGxZW3VKVBn"
      },
      "source": [
        "#### 2) Mecab 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qud-9S-MHda"
      },
      "source": [
        "#모델 정의 및 학습하기\n",
        "def mec_transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"mec_transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    # 인코더에서 패딩을 위한 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='enc_padding_mask')(inputs)\n",
        "\n",
        "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "        create_look_ahead_mask,\n",
        "        output_shape=(1, None, None),\n",
        "        name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "    # 디코더에서 패딩을 위한 마스크\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='dec_padding_mask')(inputs)\n",
        "\n",
        "    # 인코더\n",
        "    enc_outputs = encoder(\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=num_layers,\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    # 디코더\n",
        "    dec_outputs = decoder(\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=num_layers,\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    # 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn0we0xiMXVz",
        "outputId": "b46b58c5-d509-4810-a47e-41224d0b8611"
      },
      "source": [
        "#모델 생성\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "mec_model = mec_transformer(\n",
        "    vocab_size=mec_VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "mec_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"mec_transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 512)    12969984    inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, None, 512)    19279872    dec_inputs[0][0]                 \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 6840)   3508920     decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 35,758,776\n",
            "Trainable params: 35,758,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obzxAkpxe6ih"
      },
      "source": [
        "#손실함수\n",
        "def loss_function(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHpo9lC8e6ih"
      },
      "source": [
        "#커스텀된 학습률\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Kh59wWhoe6ih",
        "outputId": "bee7d5e3-b795-4ee7-cad5-cdcb44becbfb"
      },
      "source": [
        "#커스텀 학습률 스케줄링 계획 시각화\n",
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9dPOChbe6ih"
      },
      "source": [
        "#모델 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "sub_model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZUSZCNZKVBo"
      },
      "source": [
        "#### 3) 각 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw8k_GLCe6ih",
        "outputId": "71e34caa-4d32-47f0-86ff-391d95a3977a"
      },
      "source": [
        "# 훈련하기\n",
        "# 인퍼런스 과정을 반복할때 사용할 가중치를 따로 저장합니다.\n",
        "# sub_checkpoint_path = \"/content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\"\n",
        "sub_checkpoint_path = \"/aiffel/aiffel/transformer_chatbot/data/Model_save/sub_cp.ckpt\"\n",
        "sub_checkpoint_dir = os.path.dirname(sub_checkpoint_path)\n",
        "# 모델의 가중치를 저장하는 콜백 만들기\n",
        "sub_cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=sub_checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "EPOCHS = 50\n",
        "sub_model.fit(sub_dataset, epochs=EPOCHS, callbacks=[sub_cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 108s 464ms/step - loss: 1.3488 - accuracy: 0.0263\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 1.0737 - accuracy: 0.0494\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.9861 - accuracy: 0.0506\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.9413 - accuracy: 0.0525\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.9088 - accuracy: 0.0544\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.8713 - accuracy: 0.0567\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.8301 - accuracy: 0.0592\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.7809 - accuracy: 0.0622\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 86s 463ms/step - loss: 0.7269 - accuracy: 0.0664\n",
            "\n",
            "Epoch 00009: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.6686 - accuracy: 0.0714\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.6093 - accuracy: 0.0777\n",
            "\n",
            "Epoch 00011: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.5486 - accuracy: 0.0849\n",
            "\n",
            "Epoch 00012: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.4919 - accuracy: 0.0916\n",
            "\n",
            "Epoch 00013: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.4404 - accuracy: 0.0985\n",
            "\n",
            "Epoch 00014: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.3942 - accuracy: 0.1045\n",
            "\n",
            "Epoch 00015: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.3545 - accuracy: 0.1098\n",
            "\n",
            "Epoch 00016: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.3247 - accuracy: 0.1136\n",
            "\n",
            "Epoch 00017: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.3010 - accuracy: 0.1165\n",
            "\n",
            "Epoch 00018: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.2807 - accuracy: 0.1194\n",
            "\n",
            "Epoch 00019: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.2669 - accuracy: 0.1213\n",
            "\n",
            "Epoch 00020: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.2565 - accuracy: 0.1227\n",
            "\n",
            "Epoch 00021: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.2491 - accuracy: 0.1237\n",
            "\n",
            "Epoch 00022: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.2338 - accuracy: 0.1259\n",
            "\n",
            "Epoch 00023: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.2190 - accuracy: 0.1285\n",
            "\n",
            "Epoch 00024: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.2054 - accuracy: 0.1307\n",
            "\n",
            "Epoch 00025: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1920 - accuracy: 0.1328\n",
            "\n",
            "Epoch 00026: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1826 - accuracy: 0.1342\n",
            "\n",
            "Epoch 00027: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.1748 - accuracy: 0.1353\n",
            "\n",
            "Epoch 00028: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.1630 - accuracy: 0.1377\n",
            "\n",
            "Epoch 00029: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.1570 - accuracy: 0.1387\n",
            "\n",
            "Epoch 00030: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.1493 - accuracy: 0.1401\n",
            "\n",
            "Epoch 00031: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1420 - accuracy: 0.1412\n",
            "\n",
            "Epoch 00032: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1357 - accuracy: 0.1424\n",
            "\n",
            "Epoch 00033: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1303 - accuracy: 0.1431\n",
            "\n",
            "Epoch 00034: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1239 - accuracy: 0.1445\n",
            "\n",
            "Epoch 00035: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 86s 462ms/step - loss: 0.1196 - accuracy: 0.1453\n",
            "\n",
            "Epoch 00036: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1152 - accuracy: 0.1462\n",
            "\n",
            "Epoch 00037: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.1097 - accuracy: 0.1472\n",
            "\n",
            "Epoch 00038: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.1049 - accuracy: 0.1483\n",
            "\n",
            "Epoch 00039: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 86s 463ms/step - loss: 0.1010 - accuracy: 0.1491\n",
            "\n",
            "Epoch 00040: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.0967 - accuracy: 0.1500\n",
            "\n",
            "Epoch 00041: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 86s 464ms/step - loss: 0.0926 - accuracy: 0.1509\n",
            "\n",
            "Epoch 00042: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 43/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.0886 - accuracy: 0.1518\n",
            "\n",
            "Epoch 00043: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 86s 463ms/step - loss: 0.0854 - accuracy: 0.1525\n",
            "\n",
            "Epoch 00044: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.0826 - accuracy: 0.1530\n",
            "\n",
            "Epoch 00045: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.0783 - accuracy: 0.1540\n",
            "\n",
            "Epoch 00046: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.0753 - accuracy: 0.1545\n",
            "\n",
            "Epoch 00047: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 0.0717 - accuracy: 0.1554\n",
            "\n",
            "Epoch 00048: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.0699 - accuracy: 0.1560\n",
            "\n",
            "Epoch 00049: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 86s 466ms/step - loss: 0.0672 - accuracy: 0.1567\n",
            "\n",
            "Epoch 00050: saving model to /content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/sub_cp.ckpt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f692769f690>"
            ]
          },
          "execution_count": 160,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH3u1iACNUMN"
      },
      "source": [
        "#모델 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "mec_model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "dJ7-aJ-nNV0r",
        "outputId": "6912944b-323f-40c4-b707-fa4a0b3a9226"
      },
      "source": [
        "#훈련하기\n",
        "# 인퍼런스 과정을 반복할때 사용할 가중치를 따로 저장합니다.\n",
        "# mec_checkpoint_path = \"/content/drive/MyDrive/aiffel/data/songys_chatbot/Model_save/mec_cp.ckpt\"\n",
        "mec_checkpoint_path = \"/aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\"\n",
        "mec_checkpoint_dir = os.path.dirname(mec_checkpoint_path)\n",
        "# 모델의 가중치를 저장하는 콜백 만들기\n",
        "mec_cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=mec_checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "EPOCHS = 50\n",
        "mec_model.fit(mec_dataset, epochs=EPOCHS, callbacks=[mec_cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 85s 460ms/step - loss: 1.2403 - accuracy: 0.0544\n",
            "\n",
            "Epoch 00001: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 86s 465ms/step - loss: 1.0644 - accuracy: 0.0697\n",
            "\n",
            "Epoch 00002: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 86s 467ms/step - loss: 0.9282 - accuracy: 0.0871\n",
            "\n",
            "Epoch 00003: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 87s 471ms/step - loss: 0.8360 - accuracy: 0.0968\n",
            "\n",
            "Epoch 00004: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.7662 - accuracy: 0.1048\n",
            "\n",
            "Epoch 00005: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.7068 - accuracy: 0.1119\n",
            "\n",
            "Epoch 00006: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.6543 - accuracy: 0.1188\n",
            "\n",
            "Epoch 00007: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.6043 - accuracy: 0.1254\n",
            "\n",
            "Epoch 00008: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.5587 - accuracy: 0.1322\n",
            "\n",
            "Epoch 00009: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 87s 473ms/step - loss: 0.5145 - accuracy: 0.1382\n",
            "\n",
            "Epoch 00010: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.4742 - accuracy: 0.1442\n",
            "\n",
            "Epoch 00011: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.4374 - accuracy: 0.1502\n",
            "\n",
            "Epoch 00012: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.4017 - accuracy: 0.1555\n",
            "\n",
            "Epoch 00013: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.3751 - accuracy: 0.1590\n",
            "\n",
            "Epoch 00014: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.3483 - accuracy: 0.1634\n",
            "\n",
            "Epoch 00015: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.3277 - accuracy: 0.1660\n",
            "\n",
            "Epoch 00016: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.3086 - accuracy: 0.1688\n",
            "\n",
            "Epoch 00017: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.2957 - accuracy: 0.1707\n",
            "\n",
            "Epoch 00018: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.2832 - accuracy: 0.1726\n",
            "\n",
            "Epoch 00019: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.2760 - accuracy: 0.1736\n",
            "\n",
            "Epoch 00020: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.2673 - accuracy: 0.1747\n",
            "\n",
            "Epoch 00021: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.2528 - accuracy: 0.1774\n",
            "\n",
            "Epoch 00022: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 87s 471ms/step - loss: 0.2357 - accuracy: 0.1809\n",
            "\n",
            "Epoch 00023: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.2166 - accuracy: 0.1844\n",
            "\n",
            "Epoch 00024: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.2030 - accuracy: 0.1875\n",
            "\n",
            "Epoch 00025: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.1867 - accuracy: 0.1911\n",
            "\n",
            "Epoch 00026: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 87s 473ms/step - loss: 0.1745 - accuracy: 0.1939\n",
            "\n",
            "Epoch 00027: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.1644 - accuracy: 0.1961\n",
            "\n",
            "Epoch 00028: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.1537 - accuracy: 0.1985\n",
            "\n",
            "Epoch 00029: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.1436 - accuracy: 0.2008\n",
            "\n",
            "Epoch 00030: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 88s 476ms/step - loss: 0.1362 - accuracy: 0.2026\n",
            "\n",
            "Epoch 00031: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 88s 478ms/step - loss: 0.1291 - accuracy: 0.2042\n",
            "\n",
            "Epoch 00032: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 87s 473ms/step - loss: 0.1205 - accuracy: 0.2067\n",
            "\n",
            "Epoch 00033: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 87s 471ms/step - loss: 0.1134 - accuracy: 0.2082\n",
            "\n",
            "Epoch 00034: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.1087 - accuracy: 0.2093\n",
            "\n",
            "Epoch 00035: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.1026 - accuracy: 0.2109\n",
            "\n",
            "Epoch 00036: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0966 - accuracy: 0.2125\n",
            "\n",
            "Epoch 00037: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.0926 - accuracy: 0.2136\n",
            "\n",
            "Epoch 00038: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.0885 - accuracy: 0.2148\n",
            "\n",
            "Epoch 00039: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0854 - accuracy: 0.2155\n",
            "\n",
            "Epoch 00040: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.0809 - accuracy: 0.2167\n",
            "\n",
            "Epoch 00041: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.0780 - accuracy: 0.2175\n",
            "\n",
            "Epoch 00042: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0749 - accuracy: 0.2184\n",
            "\n",
            "Epoch 00043: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 87s 472ms/step - loss: 0.0726 - accuracy: 0.2193\n",
            "\n",
            "Epoch 00044: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 88s 475ms/step - loss: 0.0680 - accuracy: 0.2205\n",
            "\n",
            "Epoch 00045: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0679 - accuracy: 0.2204\n",
            "\n",
            "Epoch 00046: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0640 - accuracy: 0.2215\n",
            "\n",
            "Epoch 00047: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 88s 473ms/step - loss: 0.0619 - accuracy: 0.2221\n",
            "\n",
            "Epoch 00048: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0588 - accuracy: 0.2230\n",
            "\n",
            "Epoch 00049: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 88s 474ms/step - loss: 0.0573 - accuracy: 0.2235\n",
            "\n",
            "Epoch 00050: saving model to /aiffel/aiffel/transformer_chatbot/data/Model_save/mec_cp.ckpt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff34d1c2cd0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWR4edmee6ii"
      },
      "source": [
        "***\n",
        "### [Step 4] 모델 평가하기\n",
        "- Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다.  \n",
        "\n",
        "#### 1) SubwordTextEncoder Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YswDYPWQ6Jpg",
        "outputId": "9feb5c1a-4b22-4f13-af87-be0a4918c10d"
      },
      "source": [
        "sub_model.load_weights(sub_checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff34b1ed5d0>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVZShztme6ii"
      },
      "source": [
        "#챗봇 테스트하기\n",
        "def sub_decoder_inference(sentence):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "    sentence = tf.expand_dims(\n",
        "        sub_START_TOKEN + sub_tokenizer.encode(sentence) + sub_END_TOKEN, axis=0)\n",
        "\n",
        "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "    sub_output_sequence = tf.expand_dims(sub_START_TOKEN, 0)\n",
        "\n",
        "    # 디코더의 인퍼런스 단계\n",
        "    for i in range(MAX_LENGTH):\n",
        "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "        sub_predictions = sub_model(inputs=[sentence, sub_output_sequence], training=False)\n",
        "        sub_predictions = sub_predictions[:, -1:, :]\n",
        "\n",
        "        # 현재 예측한 단어의 정수\n",
        "        sub_predicted_id = tf.cast(tf.argmax(sub_predictions, axis=-1), tf.int32)\n",
        "\n",
        "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "        if tf.equal(sub_predicted_id, sub_END_TOKEN[0]):\n",
        "            break\n",
        "\n",
        "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "        sub_output_sequence = tf.concat([sub_output_sequence, sub_predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(sub_output_sequence, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYmblzL0e6ii"
      },
      "source": [
        "#챗봇의 대답을 얻는 함수\n",
        "def sub_sentence_generation(sentence):\n",
        "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "    sub_prediction = sub_decoder_inference(sentence)\n",
        "\n",
        "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "    sub_predicted_sentence = sub_tokenizer.decode(\n",
        "        [i for i in sub_prediction if i < sub_tokenizer.vocab_size])\n",
        "\n",
        "    print('입력 : {}'.format(sentence))\n",
        "    print('출력 : {}'.format(sub_predicted_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3C4rmBKe6ii"
      },
      "source": [
        "-모델 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EmzVxHVe6ii",
        "outputId": "d303cd72-121d-405a-b250-6160ea0e5e76"
      },
      "source": [
        "sub_sentence_generation('잠이 오네')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : 잠이 오네\n",
            "출력 : 잠시 쉬었다 가세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65Y9H-KLe6ii",
        "outputId": "ccc0f9c1-602a-427d-aadb-0647a67ba893"
      },
      "source": [
        "sub_sentence_generation('배고프다')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : 배고프다\n",
            "출력 : 저도 밥 먹고 싶어요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7ujHitKVBq"
      },
      "source": [
        "#### 2) Mecab Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw5K2XhXVu2Q",
        "outputId": "4e1cd30a-3a2a-46ad-fea1-0fa9c483f6f4"
      },
      "source": [
        "mec_model.load_weights(mec_checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff34ad9a050>"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXeV5TrovuCC"
      },
      "source": [
        "#챗봇 테스트하기\n",
        "def mec_decoder_inference(sentence, word_to_index):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "    sentence = tf.expand_dims(\n",
        "        [word_to_index['<BOS>']] + get_encoded_sentence(sentence, word_to_index) + [word_to_index['<EOS>']], axis=0)\n",
        "\n",
        "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "    mec_output_sequence = tf.expand_dims([word_to_index['<BOS>']], 0)\n",
        "\n",
        "    # 디코더의 인퍼런스 단계\n",
        "    for i in range(MAX_LENGTH):\n",
        "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "        mec_predictions = mec_model(inputs=[sentence, mec_output_sequence], training=False)\n",
        "        mec_predictions = mec_predictions[:, -1:, :]\n",
        "\n",
        "        # 현재 예측한 단어의 정수\n",
        "        mec_predicted_id = tf.cast(tf.argmax(mec_predictions, axis=-1), tf.int32)\n",
        "\n",
        "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "        if tf.equal(mec_predicted_id, word_to_index['<EOS>']):\n",
        "            break\n",
        "\n",
        "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "        mec_output_sequence = tf.concat([mec_output_sequence, mec_predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(mec_output_sequence, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yztmCcMGrNc"
      },
      "source": [
        "#챗봇의 대답을 얻는 함수\n",
        "def mec_sentence_generation(sentence, word_to_index):\n",
        "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "    mec_prediction = mec_decoder_inference(sentence, word_to_index)\n",
        "\n",
        "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "    \n",
        "    mec_predicted_sentence = [index_to_word[int(i)] for i in mec_prediction if i < len(word_to_index)]\n",
        "\n",
        "    print('입력 : {}'.format(sentence))\n",
        "    print('출력 : {}'.format(mec_predicted_sentence[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "tt11Yd6nHfKT",
        "outputId": "8b835f92-8272-4e71-b4b0-78a3974c7897"
      },
      "source": [
        "mec_sentence_generation('잠이 오네', word_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : 잠이 오네\n",
            "출력 : ['잠', '이', '최고', '의', '보약', '이', '에요', '.', '노력', '해', '보', '세요', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4LhCYr7KVBr",
        "outputId": "92bbf5a2-37cf-4e6d-dd91-4e1f684e1bc4"
      },
      "source": [
        "mec_sentence_generation('배고프다',word_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : 배고프다\n",
            "출력 : ['시원', '하', '게', '씻', '고', '오', '세요', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLJ1gskFKVBr"
      },
      "source": [
        "결과를 비교해보았을 때 SubwordTextEncoder보다 Mecab이 더 자연스러운 문장을 만들어내는 경우도 있으나, 반대의 경우도 있었습니다.  \n",
        "SbwordTextEncoder의 경우 띄어쓰기를 기반으로 학습이 진행되기때문에 문장형성에도 이러한 부분이 반영됩니다.  \n",
        "반면에 Mecab의 경우 형태소를 기반으로 학습이 진행되기 때문에 띄어쓰기를 따로 토큰으로 형성해야 합니다.  \n",
        "추가적으로 inference과정에서 해당부분을 반영할 수 있는 함수를 구현해주어야 할 것으로 보입니다.  \n",
        "해당 미니프로젝트는 이를 고려하지않고 SubwordTextEncoder와 Mecab을 단순 비교하는 과정을 거쳤기때문에  \n",
        "성능부분에 크게 차이가 보이지는 않는 결과를 보인 것으로 판단됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF6fSwt5f3J-"
      },
      "source": [
        "***\n",
        "### [Last Step] Reference\n",
        "[송영숙님의 챗봇 데이터](https://github.com/songys/Chatbot_data)  \n",
        "[Jake님의 블로그(구글드라이브)](http://growthj.link/python-%EA%B5%AC%EA%B8%80-colab%EC%9C%BC%EB%A1%9C-pd-read-csv-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/)  \n",
        "[형태소 분석에 관해서](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=sw4r&logNo=221097202405)  \n",
        "[형태소 분석기 비교(by ratsgo)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/05/10/postag/)  \n",
        "[형태소 분석기 비교(mecab 포함)](https://iostream.tistory.com/144)  \n",
        "[PyTorch로 시작하는 딥 러닝 입문](https://wikidocs.net/64517)  \n",
        "[seq2seq 및 교사강요](https://bkshin.tistory.com/entry/NLP-13-%EC%8B%9C%ED%80%80%EC%8A%A4%ED%88%AC%EC%8B%9C%ED%80%80%EC%8A%A4seq2seq?category=1097026)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh-6lxxse6ij"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}